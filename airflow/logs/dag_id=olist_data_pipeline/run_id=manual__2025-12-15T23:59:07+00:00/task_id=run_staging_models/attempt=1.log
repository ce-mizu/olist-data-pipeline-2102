{"timestamp":"2025-12-15T23:59:17.164350Z","level":"info","event":"DAG bundles loaded: dags-folder, example_dags","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager","filename":"manager.py","lineno":179}
{"timestamp":"2025-12-15T23:59:17.165078Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/olist_data_pipeline.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2025-12-15T23:59:17.201395Z","level":"info","event":"Task instance is in running state","logger":"task.stdout"}
{"timestamp":"2025-12-15T23:59:17.201602Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.QUEUED","logger":"task.stdout"}
{"timestamp":"2025-12-15T23:59:17.201761Z","level":"info","event":"Current task name:run_staging_models","logger":"task.stdout"}
{"timestamp":"2025-12-15T23:59:17.201885Z","level":"info","event":"Dag name:olist_data_pipeline","logger":"task.stdout"}
{"timestamp":"2025-12-15T23:59:17.202504Z","level":"info","event":"Tmp dir root location: /tmp","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":78}
{"timestamp":"2025-12-15T23:59:17.203829Z","level":"info","event":"Running command: ['/usr/bin/bash', '-c', 'cd /opt/airflow/dbt && dbt run --select staging --vars \\'{\"batch_hours\": 1}\\' --profiles-dir /opt/airflow/dbt']","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":80}
{"timestamp":"2025-12-15T23:59:17.204623Z","level":"info","event":"Output:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":92}
{"timestamp":"2025-12-15T23:59:19.183957Z","level":"info","event":"\u001b[0m23:59:19  Running with dbt=1.9.1","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-15T23:59:22.503036Z","level":"info","event":"\u001b[0m23:59:22  Registered adapter: bigquery=1.9.1","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-15T23:59:22.853547Z","level":"info","event":"\u001b[0m23:59:22  [\u001b[33mWARNING\u001b[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-15T23:59:22.853715Z","level":"info","event":"There are 3 unused configuration paths:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-15T23:59:22.853775Z","level":"info","event":"- models.olist_data_pipeline.marts","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-15T23:59:22.853840Z","level":"info","event":"- seeds.olist_data_pipeline","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-15T23:59:22.853879Z","level":"info","event":"- snapshots.olist_data_pipeline","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-15T23:59:23.064004Z","level":"info","event":"\u001b[0m23:59:23  Found 11 models, 33 data tests, 9 sources, 611 macros","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-15T23:59:23.067508Z","level":"info","event":"\u001b[0m23:59:23","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-15T23:59:23.067953Z","level":"info","event":"\u001b[0m23:59:23  Concurrency: 4 threads (target='dev')","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-15T23:59:23.068383Z","level":"info","event":"\u001b[0m23:59:23","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-15T23:59:23.967459Z","level":"info","event":"\u001b[0m23:59:23  1 of 9 START sql table model staging.stg_customers ............................. [RUN]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-15T23:59:23.970391Z","level":"info","event":"\u001b[0m23:59:23  2 of 9 START sql table model staging.stg_geolocation ........................... [RUN]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-15T23:59:23.974889Z","level":"info","event":"\u001b[0m23:59:23  4 of 9 START sql table model staging.stg_order_payments ........................ [RUN]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-15T23:59:23.975578Z","level":"info","event":"\u001b[0m23:59:23  3 of 9 START sql table model staging.stg_order_items ........................... [RUN]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-15T23:59:24.668121Z","level":"info","event":"/home/airflow/.local/lib/python3.12/site-packages/dbt/adapters/bigquery/connections.py:570: FutureWarning: job_retry must be explicitly set to None if job_id is set.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-15T23:59:24.668269Z","level":"info","event":"BigQuery cannot retry a failed job by using the exact","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-15T23:59:24.668318Z","level":"info","event":"same ID. Setting job_id without explicitly disabling","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-15T23:59:24.668355Z","level":"info","event":"job_retry will raise an error in the future. To avoid this","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-15T23:59:24.668391Z","level":"info","event":"warning, either use job_id_prefix instead (preferred) or","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-15T23:59:24.668424Z","level":"info","event":"set job_retry=None.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-15T23:59:24.668457Z","level":"info","event":"  query_job = client.query(","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-15T23:59:27.221366Z","level":"info","event":"\u001b[0m23:59:27  1 of 9 OK created sql table model staging.stg_customers ........................ [\u001b[32mCREATE TABLE (99.4k rows, 8.8 MiB processed)\u001b[0m in 3.25s]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-15T23:59:27.224408Z","level":"info","event":"\u001b[0m23:59:27  5 of 9 START sql table model staging.stg_order_reviews ......................... [RUN]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-15T23:59:27.477939Z","level":"info","event":"\u001b[0m23:59:27  4 of 9 OK created sql table model staging.stg_order_payments ................... [\u001b[32mCREATE TABLE (103.9k rows, 6.9 MiB processed)\u001b[0m in 3.50s]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-15T23:59:27.480104Z","level":"info","event":"\u001b[0m23:59:27  6 of 9 START sql incremental model staging.stg_orders .......................... [RUN]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-15T23:59:27.539825Z","level":"info","event":"/home/airflow/.local/lib/python3.12/site-packages/dbt/adapters/bigquery/connections.py:570: FutureWarning: job_retry must be explicitly set to None if job_id is set.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-15T23:59:27.539992Z","level":"info","event":"BigQuery cannot retry a failed job by using the exact","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-15T23:59:27.540049Z","level":"info","event":"same ID. Setting job_id without explicitly disabling","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-15T23:59:27.540093Z","level":"info","event":"job_retry will raise an error in the future. To avoid this","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-15T23:59:27.540132Z","level":"info","event":"warning, either use job_id_prefix instead (preferred) or","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-15T23:59:27.540169Z","level":"info","event":"set job_retry=None.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-15T23:59:27.540206Z","level":"info","event":"  query_job = client.query(","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-15T23:59:27.721510Z","level":"info","event":"\u001b[0m23:59:27  3 of 9 OK created sql table model staging.stg_order_items ...................... [\u001b[32mCREATE TABLE (112.7k rows, 14.4 MiB processed)\u001b[0m in 3.74s]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-15T23:59:27.723853Z","level":"info","event":"\u001b[0m23:59:27  7 of 9 START sql table model staging.stg_product_category_translation .......... [RUN]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-15T23:59:27.986514Z","level":"info","event":"/home/airflow/.local/lib/python3.12/site-packages/dbt/adapters/bigquery/connections.py:570: FutureWarning: job_retry must be explicitly set to None if job_id is set.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-15T23:59:27.986666Z","level":"info","event":"BigQuery cannot retry a failed job by using the exact","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-15T23:59:27.986717Z","level":"info","event":"same ID. Setting job_id without explicitly disabling","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-15T23:59:27.986761Z","level":"info","event":"job_retry will raise an error in the future. To avoid this","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-15T23:59:27.986813Z","level":"info","event":"warning, either use job_id_prefix instead (preferred) or","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-15T23:59:27.986850Z","level":"info","event":"set job_retry=None.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-15T23:59:27.986884Z","level":"info","event":"  query_job = client.query(","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-15T23:59:28.009558Z","level":"info","event":"\u001b[0m23:59:28  2 of 9 OK created sql table model staging.stg_geolocation ...................... [\u001b[32mCREATE TABLE (1.0m rows, 38.7 MiB processed)\u001b[0m in 4.03s]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-15T23:59:28.011571Z","level":"info","event":"\u001b[0m23:59:28  8 of 9 START sql table model staging.stg_products .............................. [RUN]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-15T23:59:28.462366Z","level":"info","event":"/home/airflow/.local/lib/python3.12/site-packages/dbt/adapters/bigquery/connections.py:570: FutureWarning: job_retry must be explicitly set to None if job_id is set.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-15T23:59:28.462531Z","level":"info","event":"BigQuery cannot retry a failed job by using the exact","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-15T23:59:28.462584Z","level":"info","event":"same ID. Setting job_id without explicitly disabling","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-15T23:59:28.462634Z","level":"info","event":"job_retry will raise an error in the future. To avoid this","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-15T23:59:28.462672Z","level":"info","event":"warning, either use job_id_prefix instead (preferred) or","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-15T23:59:28.462706Z","level":"info","event":"set job_retry=None.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-15T23:59:28.462745Z","level":"info","event":"  query_job = client.query(","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-15T23:59:30.067620Z","level":"info","event":"\u001b[0m23:59:30  7 of 9 OK created sql table model staging.stg_product_category_translation ..... [\u001b[32mCREATE TABLE (72.0 rows, 2.6 KiB processed)\u001b[0m in 2.34s]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-15T23:59:30.069823Z","level":"info","event":"\u001b[0m23:59:30  9 of 9 START sql table model staging.stg_sellers ............................... [RUN]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-15T23:59:30.464840Z","level":"info","event":"/home/airflow/.local/lib/python3.12/site-packages/dbt/adapters/bigquery/connections.py:570: FutureWarning: job_retry must be explicitly set to None if job_id is set.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-15T23:59:30.464991Z","level":"info","event":"BigQuery cannot retry a failed job by using the exact","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-15T23:59:30.465040Z","level":"info","event":"same ID. Setting job_id without explicitly disabling","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-15T23:59:30.465078Z","level":"info","event":"job_retry will raise an error in the future. To avoid this","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-15T23:59:30.465114Z","level":"info","event":"warning, either use job_id_prefix instead (preferred) or","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-15T23:59:30.465147Z","level":"info","event":"set job_retry=None.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-15T23:59:30.465180Z","level":"info","event":"  query_job = client.query(","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-15T23:59:30.506150Z","level":"info","event":"\u001b[0m23:59:30  8 of 9 OK created sql table model staging.stg_products ......................... [\u001b[32mCREATE TABLE (33.0k rows, 3.3 MiB processed)\u001b[0m in 2.49s]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-15T23:59:30.544886Z","level":"info","event":"\u001b[0m23:59:30  5 of 9 OK created sql table model staging.stg_order_reviews .................... [\u001b[32mCREATE TABLE (95.4k rows, 10.9 MiB processed)\u001b[0m in 3.32s]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-15T23:59:33.124741Z","level":"info","event":"\u001b[0m23:59:33  6 of 9 OK created sql incremental model staging.stg_orders ..................... [\u001b[32mMERGE (0.0 rows, 12.0 MiB processed)\u001b[0m in 5.64s]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-15T23:59:50.062302Z","level":"info","event":"\u001b[0m23:59:50  9 of 9 OK created sql table model staging.stg_sellers .......................... [\u001b[32mCREATE TABLE (3.1k rows, 175.8 KiB processed)\u001b[0m in 19.99s]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-15T23:59:50.107307Z","level":"info","event":"\u001b[0m23:59:50","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-15T23:59:50.107818Z","level":"info","event":"\u001b[0m23:59:50  Finished running 1 incremental model, 8 table models in 0 hours 0 minutes and 27.04 seconds (27.04s).","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-15T23:59:50.164073Z","level":"info","event":"\u001b[0m23:59:50","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-15T23:59:50.164672Z","level":"info","event":"\u001b[0m23:59:50  \u001b[32mCompleted successfully\u001b[0m","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-15T23:59:50.165224Z","level":"info","event":"\u001b[0m23:59:50","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-15T23:59:50.165825Z","level":"info","event":"\u001b[0m23:59:50  Done. PASS=9 WARN=0 ERROR=0 SKIP=0 TOTAL=9","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-15T23:59:50.999988Z","level":"info","event":"Command exited with return code 0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":103}
{"timestamp":"2025-12-15T23:59:51.000628Z","level":"info","event":"Pushing xcom","ti":"RuntimeTaskInstance(id=UUID('019b2473-18c8-7f70-81e2-ef6629dce26d'), task_id='run_staging_models', dag_id='olist_data_pipeline', run_id='manual__2025-12-15T23:59:07+00:00', try_number=1, dag_version_id=UUID('019b246e-abf3-7b74-9142-6ad3b4be09c6'), map_index=-1, hostname='5248545eba8b', context_carrier={}, task=<Task(BashOperator): run_staging_models>, bundle_instance=LocalDagBundle(name=dags-folder), max_tries=2, start_date=datetime.datetime(2025, 12, 15, 23, 59, 16, 796986, tzinfo=datetime.timezone.utc), end_date=None, state=<TaskInstanceState.RUNNING: 'running'>, is_mapped=False, rendered_map_index=None)","logger":"task","filename":"task_runner.py","lineno":1370}
{"timestamp":"2025-12-15T23:59:51.029593Z","level":"info","event":"Task instance in success state","logger":"task.stdout"}
{"timestamp":"2025-12-15T23:59:51.029787Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.RUNNING","logger":"task.stdout"}
{"timestamp":"2025-12-15T23:59:51.029947Z","level":"info","event":"Task operator:<Task(BashOperator): run_staging_models>","logger":"task.stdout"}
